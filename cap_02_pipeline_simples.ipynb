{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 2 – End-to-end Machine Learning project**\n",
    "\n",
    "*Welcome to Machine Learning Housing Corp.! Your task is to predict median house values in Californian districts, given a number of features from these districts.*\n",
    "\n",
    "*This notebook contains all the sample code and solutions to the exercices in chapter 2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T22:27:55.589766Z",
     "start_time": "2020-12-15T22:27:55.581747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ------- Pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin # para Criar custom transformer\n",
    "from sklearn.compose import ColumnTransformer # para unificar os pipelines\n",
    "\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "\n",
    "# to make this notebook's output identical at every run\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:51:29.511598Z",
     "start_time": "2020-12-15T21:51:29.503580Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:51:31.271210Z",
     "start_time": "2020-12-15T21:51:29.740009Z"
    }
   },
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T21:51:40.130191Z",
     "start_time": "2020-12-15T21:51:31.273608Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    print(\"\\n Lendo arquivo do caminho:\",csv_path)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T22:25:02.709816Z",
     "start_time": "2020-12-15T22:25:02.670955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lendo arquivo do caminho: datasets/housing/housing.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_housing_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split\n",
    "    - Lembre que o split permite multiplos dfs\n",
    "    - Precisa ser stratificado?\n",
    "    - Vai incluir validação? Calibração de probabilidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T22:25:04.602967Z",
     "start_time": "2020-12-15T22:25:04.485410Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "OPCIONAL\n",
    "Criando variável para extratificar o split\n",
    "'''\n",
    "\n",
    "df[\"income_cat\"] = pd.cut(df[\"median_income\"],\n",
    "                          bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                          labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T22:36:09.804020Z",
     "start_time": "2020-12-15T22:36:09.797056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:       (20640, 11)\n",
      "df_train.shape: (16512, 11)\n",
      "df_test.shape:  (4128, 11)\n"
     ]
    }
   ],
   "source": [
    "# padrão 20% para teste\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state=75)\n",
    "\n",
    "print(\"df.shape:      \",df.shape)\n",
    "print(\"df_train.shape:\",df_train.shape)\n",
    "print(\"df_test.shape: \",df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T22:36:10.422921Z",
     "start_time": "2020-12-15T22:36:10.397961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape:       (20640, 11)\n",
      "df_train.shape: (16512, 11)\n",
      "df_test.shape:  (4128, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350581</td>\n",
       "      <td>0.350594</td>\n",
       "      <td>0.350533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.318847</td>\n",
       "      <td>0.318859</td>\n",
       "      <td>0.318798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176308</td>\n",
       "      <td>0.176296</td>\n",
       "      <td>0.176357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114438</td>\n",
       "      <td>0.114402</td>\n",
       "      <td>0.114583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039826</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.039729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original     train      test\n",
       "3  0.350581  0.350594  0.350533\n",
       "2  0.318847  0.318859  0.318798\n",
       "4  0.176308  0.176296  0.176357\n",
       "5  0.114438  0.114402  0.114583\n",
       "1  0.039826  0.039850  0.039729"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CODIGO EXLCUSIVO\n",
    "\n",
    "Split Stratificado\n",
    "'''\n",
    "\n",
    "# padrão 20% para teste\n",
    "df_train, df_test = train_test_split(df,\n",
    "                                     test_size = 0.2,\n",
    "                                     random_state=75,\n",
    "                                     stratify = df[\"income_cat\"])\n",
    "\n",
    "print(\"df.shape:      \",df.shape)\n",
    "print(\"df_train.shape:\",df_train.shape)\n",
    "print(\"df_test.shape: \",df_test.shape)\n",
    "\n",
    "# Checando a estratificação\n",
    "pd.DataFrame({\"original\" : df[\"income_cat\"].value_counts(normalize=True),\n",
    "              \"train\" : df_train[\"income_cat\"].value_counts(normalize=True),\n",
    "              \"test\" : df_test[\"income_cat\"].value_counts(normalize=True)\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T22:36:11.615352Z",
     "start_time": "2020-12-15T22:36:10.977393Z"
    }
   },
   "outputs": [],
   "source": [
    "# removendo a variavel criada para estratificação\n",
    "for set_ in (df_train, df_test):\n",
    "    set_ = set_.drop(\"income_cat\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T02:30:08.866114Z",
     "start_time": "2020-12-16T02:30:08.861095Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "y_train = df_train[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T02:31:29.416566Z",
     "start_time": "2020-12-16T02:31:29.409579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting numerical columns\n",
    "cols_num = X_train.select_dtypes(include='number').columns # all numericals\n",
    "list(cols_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T02:32:11.981772Z",
     "start_time": "2020-12-16T02:32:11.974790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ocean_proximity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting categorical columns\n",
    "cols_cat = X_train.select_dtypes(include='object').columns\n",
    "list(cols_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando uma função para adicionar variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.809410Z",
     "start_time": "2020-12-15T00:13:11.366Z"
    }
   },
   "outputs": [],
   "source": [
    "# column index\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "https://stackoverflow.com/questions/54646709/sklearn-pipeline-get-feature-names-after-onehotencode-in-columntransformer\n",
    "\n",
    "https://stackoverflow.com/questions/57528350/can-you-consistently-keep-track-of-column-labels-using-sklearns-transformer-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>income_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7758</th>\n",
       "      <td>-118.13</td>\n",
       "      <td>33.91</td>\n",
       "      <td>34.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>4.9107</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8846</th>\n",
       "      <td>-118.40</td>\n",
       "      <td>34.10</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3979.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>15.0001</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11828</th>\n",
       "      <td>-121.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.9891</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8656</th>\n",
       "      <td>-118.38</td>\n",
       "      <td>33.85</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4430.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>2131.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>4.9384</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>-117.21</td>\n",
       "      <td>32.81</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2496.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>5.5413</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>-121.99</td>\n",
       "      <td>39.15</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>3266.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>2.7137</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9193</th>\n",
       "      <td>-119.53</td>\n",
       "      <td>37.34</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4047.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>2.3482</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>-118.32</td>\n",
       "      <td>34.09</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>1.6331</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13858</th>\n",
       "      <td>-117.27</td>\n",
       "      <td>34.49</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2344.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>4.7361</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12303</th>\n",
       "      <td>-116.75</td>\n",
       "      <td>33.83</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5277.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "7758     -118.13     33.91                34.0        916.0           162.0   \n",
       "8846     -118.40     34.10                27.0       3979.0           510.0   \n",
       "11828    -121.00     39.00                 4.0        170.0            23.0   \n",
       "8656     -118.38     33.85                28.0       4430.0           928.0   \n",
       "14631    -117.21     32.81                26.0       2496.0           407.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "1244     -121.99     39.15                17.0       6440.0          1204.0   \n",
       "9193     -119.53     37.34                26.0       4047.0           702.0   \n",
       "4273     -118.32     34.09                34.0       2473.0          1171.0   \n",
       "13858    -117.27     34.49                 7.0       2344.0           351.0   \n",
       "12303    -116.75     33.83                16.0       5277.0          1070.0   \n",
       "\n",
       "       population  households  median_income ocean_proximity income_cat  \n",
       "7758        552.0       164.0         4.9107       <1H OCEAN          4  \n",
       "8846       1351.0       520.0        15.0001       <1H OCEAN          5  \n",
       "11828        93.0        27.0        10.9891          INLAND          5  \n",
       "8656       2131.0       885.0         4.9384       <1H OCEAN          4  \n",
       "14631      1062.0       380.0         5.5413      NEAR OCEAN          4  \n",
       "...           ...         ...            ...             ...        ...  \n",
       "1244       3266.0      1142.0         2.7137          INLAND          2  \n",
       "9193        571.0       199.0         2.3482          INLAND          2  \n",
       "4273       2655.0      1083.0         1.6331       <1H OCEAN          2  \n",
       "13858       846.0       314.0         4.7361          INLAND          4  \n",
       "12303       657.0       276.0         3.3333          INLAND          3  \n",
       "\n",
       "[16512 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('imputer', SimpleImputer(strategy='median'),\n",
       "                                 Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "      dtype='object')),\n",
       "                                ('std_scaler', StandardScaler(),\n",
       "                                 Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income'],\n",
       "      dtype='object')),\n",
       "                                ('cat', OneHotEncoder(), ['ocean_proximity'])])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs = cols_num\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([ \n",
    "        ('imputer', SimpleImputer(strategy=\"median\"), cols_num),\n",
    "#         ('attribs_adder', CombinedAttributesAdder(), cols_num),\n",
    "        ('std_scaler', StandardScaler(), cols_num),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs)],\n",
    "        # MUITA Atenção aos argumentos do ColumnTransformer:\n",
    "        remainder='drop',\n",
    "        sparse_threshold=0.3,\n",
    "        n_jobs=None,\n",
    "        transformer_weights=None,\n",
    "        verbose=False,\n",
    ")\n",
    "\n",
    "full_pipeline.fit(X_train)\n",
    "\n",
    "\n",
    "# X_train_prepared = pd.DataFrame(full_pipeline.fit_transform(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transformer imputer (type SimpleImputer) does not provide get_feature_names.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-5ba489698f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_feature_names'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 raise AttributeError(\"Transformer %s (type %s) does not \"\n\u001b[0m\u001b[1;32m    372\u001b[0m                                      \u001b[0;34m\"provide get_feature_names.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                                      % (str(name), type(trans).__name__))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Transformer imputer (type SimpleImputer) does not provide get_feature_names."
     ]
    }
   ],
   "source": [
    "full_pipeline.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>num1</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand  num1 category  target\n",
       "0     A   1.0        A       2\n",
       "1     B   1.0        A       4\n",
       "2     C   NaN      NaN       8\n",
       "3   NaN   0.0        D      10"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.DataFrame({'brand': ['A', 'B', 'C', np.NaN],\n",
    "                   'num1': [1, 1, np.NaN, 0],\n",
    "                   'category': ['A', 'A', np.NaN, 'D'],\n",
    "                    'target': [2, 4, 8, 10]})\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['num1']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['brand', 'category'])])),\n",
       "                ('regressor', LinearRegression())])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numeric_transformer\n",
    "numeric_features = ['num1']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# categorical transformer\n",
    "categorical_features = ['brand', 'category']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Preprocessor \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Preprocessor & Regressor\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor',  LinearRegression())])\n",
    "\n",
    "# Fit\n",
    "clf.fit(df.drop('target', 1), df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57735027,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ],\n",
       "       [ 0.57735027,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ],\n",
       "       [ 0.57735027,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ],\n",
       "       [-1.73205081,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_out(estimator, feature_in):\n",
    "    if hasattr(estimator,'get_feature_names'):\n",
    "        if isinstance(estimator, _VectorizerMixin):\n",
    "            # handling all vectorizers\n",
    "            return [f'vec_{f}' \\\n",
    "                for f in estimator.get_feature_names()]\n",
    "        else:\n",
    "            return estimator.get_feature_names(feature_in)\n",
    "    elif isinstance(estimator, SelectorMixin):\n",
    "        return np.array(feature_in)[estimator.get_support()]\n",
    "    else:\n",
    "        return feature_in\n",
    "\n",
    "\n",
    "def get_ct_feature_names(ct):\n",
    "    # handles all estimators, pipelines inside ColumnTransfomer\n",
    "    # doesn't work when remainder =='passthrough'\n",
    "    # which requires the input column names.\n",
    "    output_features = []\n",
    "\n",
    "    for name, estimator, features in ct.transformers_:\n",
    "        if name!='remainder':\n",
    "            if isinstance(estimator, Pipeline):\n",
    "                current_features = features\n",
    "                for step in estimator:\n",
    "                    current_features = get_feature_out(step, current_features)\n",
    "                features_out = current_features\n",
    "            else:\n",
    "                features_out = get_feature_out(estimator, features)\n",
    "            output_features.extend(features_out)\n",
    "        elif estimator=='passthrough':\n",
    "            print(ct._feature_names_in[features])\n",
    "            output_features.extend(ct._feature_names_in[features])\n",
    "                \n",
    "    return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame({'age': [23,12, 12, np.nan],\n",
    "                     'income': ['high','low','low','medium'],\n",
    "                      'sales': [10000, 100020, 110000, 100],\n",
    "                      'foo' : [1,0,0,1],\n",
    "                      'Gender': ['M','F', np.nan, 'F'],\n",
    "                      'anohter_cat': ['aa','bb', \"ccc\", 'a'],\n",
    "                      'y': [0,1,1,1]})\n",
    "numeric_columns = ['age']\n",
    "cat_columns     = [\"anohter_cat\",'Gender','income']\n",
    "\n",
    "\n",
    "\n",
    "numeric_pipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())\n",
    "cat_pipeline     = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "\n",
    "transformers = [\n",
    "('num', numeric_pipeline, numeric_columns),\n",
    "('cat', cat_pipeline, cat_columns),\n",
    "('simple_transformer', MinMaxScaler(), ['sales']),\n",
    "]\n",
    "\n",
    "combined_pipe = ColumnTransformer(transformers, remainder='drop',)\n",
    "\n",
    "transformed_data = combined_pipe.fit_transform(train.drop('y',1), train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sales</th>\n",
       "      <th>foo</th>\n",
       "      <th>Gender</th>\n",
       "      <th>anohter_cat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.0</td>\n",
       "      <td>high</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>low</td>\n",
       "      <td>100020</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>bb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>low</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ccc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>medium</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  income   sales  foo Gender anohter_cat  y\n",
       "0  23.0    high   10000    1      M          aa  0\n",
       "1  12.0     low  100020    0      F          bb  1\n",
       "2  12.0     low  110000    0    NaN         ccc  1\n",
       "3   NaN  medium     100    1      F           a  1"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anohter_cat_a</th>\n",
       "      <th>anohter_cat_aa</th>\n",
       "      <th>anohter_cat_bb</th>\n",
       "      <th>anohter_cat_ccc</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>income_high</th>\n",
       "      <th>income_low</th>\n",
       "      <th>income_medium</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  anohter_cat_a  anohter_cat_aa  anohter_cat_bb  anohter_cat_ccc  \\\n",
       "0  1.732051            0.0             1.0             0.0              0.0   \n",
       "1 -0.577350            0.0             0.0             1.0              0.0   \n",
       "2 -0.577350            0.0             0.0             0.0              1.0   \n",
       "3 -0.577350            1.0             0.0             0.0              0.0   \n",
       "\n",
       "   Gender_F  Gender_M  income_high  income_low  income_medium     sales  \n",
       "0       0.0       1.0          1.0         0.0            0.0  0.090082  \n",
       "1       1.0       0.0          0.0         1.0            0.0  0.909190  \n",
       "2       1.0       0.0          0.0         1.0            0.0  1.000000  \n",
       "3       1.0       0.0          0.0         0.0            1.0  0.000000  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_data, \n",
    "             columns=get_ct_feature_names(combined_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>income_high</th>\n",
       "      <th>income_low</th>\n",
       "      <th>income_medium</th>\n",
       "      <th>sales</th>\n",
       "      <th>foo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  Gender_F  Gender_M  income_high  income_low  income_medium  \\\n",
       "0  1.732051       0.0       1.0          1.0         0.0            0.0   \n",
       "1 -0.577350       1.0       0.0          0.0         1.0            0.0   \n",
       "2 -0.577350       1.0       0.0          0.0         1.0            0.0   \n",
       "3 -0.577350       1.0       0.0          0.0         0.0            1.0   \n",
       "\n",
       "      sales  foo  \n",
       "0  0.090082  1.0  \n",
       "1  0.909190  0.0  \n",
       "2  1.000000  0.0  \n",
       "3  0.000000  1.0  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_data, \n",
    "             columns=get_ct_feature_names(combined_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>num1</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  brand  num1 category  target\n",
       "0     A   1.0        A       2\n",
       "1     B   1.0        A       4\n",
       "2     C   NaN      NaN       8\n",
       "3   NaN   0.0        D      10"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 2 num: 2 tot: 4\n"
     ]
    }
   ],
   "source": [
    "n_steps_cat = len(categorical_transformer.steps)\n",
    "n_steps_num = len(numeric_transformer.steps)\n",
    "n_steps_tot = n_steps_cat + n_steps_num \n",
    "\n",
    "print(\"cat:\", n_steps_cat, \"num:\", n_steps_num, \"tot:\", n_steps_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imputer'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer.steps[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer',\n",
       "                 SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf['preprocessor'].transformers_[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brand_A', 'brand_B', 'brand_C', 'brand_missing', 'category_A',\n",
       "       'category_D', 'category_missing'], dtype=object)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf['preprocessor'].transformers_[1][1]['onehot']\\\n",
    "                   .get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['preprocessor'].transformers_[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['preprocessor'].transformers_[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buscando a transofmração de categoricas\n",
    "clf.named_steps['preprocessor'].transformers_[0][1].named_steps['onehot'].get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.732051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7\n",
       "0  0.577350  1.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1  0.577350  0.0  1.0  0.0  0.0  1.0  0.0  0.0\n",
       "2  0.577350  0.0  0.0  1.0  0.0  0.0  0.0  1.0\n",
       "3 -1.732051  0.0  0.0  0.0  1.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 8 elements, new values have 7 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-15a4015969ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m aux.columns = ['brand_A', 'brand_B', 'brand_C', 'brand_missing', 'category_A',\n\u001b[0m\u001b[1;32m      2\u001b[0m        'category_D', 'category_missing']\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5151\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5153\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5154\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 8 elements, new values have 7 elements"
     ]
    }
   ],
   "source": [
    "aux.columns = ['brand_A', 'brand_B', 'brand_C', 'brand_missing', 'category_A',\n",
    "       'category_D', 'category_missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.814396Z",
     "start_time": "2020-12-15T00:13:11.377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('cat', OneHotEncoder(), ['ocean_proximity'])])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), ,\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "\n",
    "num_attribs = cols_num\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([ \n",
    "#         (\"num\", num_pipeline, cols_num),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs)],\n",
    "        # MUITA Atenção aos argumentos do ColumnTransformer:\n",
    "        remainder='drop',\n",
    "        sparse_threshold=0.3,\n",
    "        n_jobs=None,\n",
    "        transformer_weights=None,\n",
    "        verbose=False,\n",
    ")\n",
    "\n",
    "full_pipeline.fit(X_train)\n",
    "\n",
    "\n",
    "# X_train_prepared = pd.DataFrame(full_pipeline.fit_transform(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat__x0_<1H OCEAN',\n",
       " 'cat__x0_INLAND',\n",
       " 'cat__x0_ISLAND',\n",
       " 'cat__x0_NEAR BAY',\n",
       " 'cat__x0_NEAR OCEAN']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7dc8d6381c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "full_pipeline.named_transformers_['num'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CombinedAttributesAdder' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5405070f69a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'CombinedAttributesAdder' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "full_pipeline.named_transformers_['num'].steps[1][1].get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CombinedAttributesAdder' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-cf4aa452f187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'onehot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CombinedAttributesAdder' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "full_pipeline.named_transformers_['num'].steps[1][1]\\\n",
    "   .named_steps['onehot'].get_feature_names(categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_feature_names() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8cdff909b178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_feature_names() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "full_pipeline.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719297</td>\n",
       "      <td>-0.808004</td>\n",
       "      <td>0.428863</td>\n",
       "      <td>-0.799577</td>\n",
       "      <td>-0.900436</td>\n",
       "      <td>-0.769940</td>\n",
       "      <td>-0.880678</td>\n",
       "      <td>0.550573</td>\n",
       "      <td>0.061484</td>\n",
       "      <td>0.029981</td>\n",
       "      <td>-0.554024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.584496</td>\n",
       "      <td>-0.718942</td>\n",
       "      <td>-0.128419</td>\n",
       "      <td>0.625090</td>\n",
       "      <td>-0.064832</td>\n",
       "      <td>-0.068210</td>\n",
       "      <td>0.051887</td>\n",
       "      <td>5.878027</td>\n",
       "      <td>0.863266</td>\n",
       "      <td>-0.043355</td>\n",
       "      <td>-1.277473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.713588</td>\n",
       "      <td>1.577942</td>\n",
       "      <td>-1.959490</td>\n",
       "      <td>-1.146558</td>\n",
       "      <td>-1.234197</td>\n",
       "      <td>-1.173061</td>\n",
       "      <td>-1.239559</td>\n",
       "      <td>3.760119</td>\n",
       "      <td>0.337310</td>\n",
       "      <td>0.037488</td>\n",
       "      <td>-1.171649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594481</td>\n",
       "      <td>-0.836130</td>\n",
       "      <td>-0.048808</td>\n",
       "      <td>0.834860</td>\n",
       "      <td>0.938853</td>\n",
       "      <td>0.616833</td>\n",
       "      <td>1.008029</td>\n",
       "      <td>0.565199</td>\n",
       "      <td>-0.163434</td>\n",
       "      <td>-0.061519</td>\n",
       "      <td>-0.069204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.178619</td>\n",
       "      <td>-1.323631</td>\n",
       "      <td>-0.208031</td>\n",
       "      <td>-0.064685</td>\n",
       "      <td>-0.312151</td>\n",
       "      <td>-0.322027</td>\n",
       "      <td>-0.314852</td>\n",
       "      <td>0.883545</td>\n",
       "      <td>0.442889</td>\n",
       "      <td>-0.024570</td>\n",
       "      <td>-0.759023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507</th>\n",
       "      <td>-1.207859</td>\n",
       "      <td>1.648255</td>\n",
       "      <td>-0.924537</td>\n",
       "      <td>1.769755</td>\n",
       "      <td>1.601574</td>\n",
       "      <td>1.613658</td>\n",
       "      <td>1.681257</td>\n",
       "      <td>-0.609498</td>\n",
       "      <td>0.082382</td>\n",
       "      <td>-0.018347</td>\n",
       "      <td>-0.403925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16508</th>\n",
       "      <td>0.020329</td>\n",
       "      <td>0.799814</td>\n",
       "      <td>-0.208031</td>\n",
       "      <td>0.656719</td>\n",
       "      <td>0.396191</td>\n",
       "      <td>-0.753253</td>\n",
       "      <td>-0.788994</td>\n",
       "      <td>-0.802491</td>\n",
       "      <td>5.784696</td>\n",
       "      <td>-0.017444</td>\n",
       "      <td>-0.604461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16509</th>\n",
       "      <td>0.624437</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.428863</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>1.522335</td>\n",
       "      <td>1.077041</td>\n",
       "      <td>1.526703</td>\n",
       "      <td>-1.180081</td>\n",
       "      <td>-1.219584</td>\n",
       "      <td>-0.057354</td>\n",
       "      <td>3.854437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16510</th>\n",
       "      <td>1.148663</td>\n",
       "      <td>-0.536128</td>\n",
       "      <td>-1.720655</td>\n",
       "      <td>-0.135383</td>\n",
       "      <td>-0.446617</td>\n",
       "      <td>-0.511731</td>\n",
       "      <td>-0.487743</td>\n",
       "      <td>0.458380</td>\n",
       "      <td>0.790731</td>\n",
       "      <td>-0.034167</td>\n",
       "      <td>-0.956917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16511</th>\n",
       "      <td>1.408280</td>\n",
       "      <td>-0.845505</td>\n",
       "      <td>-1.004149</td>\n",
       "      <td>1.228818</td>\n",
       "      <td>1.279818</td>\n",
       "      <td>-0.677723</td>\n",
       "      <td>-0.587287</td>\n",
       "      <td>-0.282333</td>\n",
       "      <td>5.312479</td>\n",
       "      <td>-0.064144</td>\n",
       "      <td>-0.168978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.719297 -0.808004  0.428863 -0.799577 -0.900436 -0.769940 -0.880678   \n",
       "1      0.584496 -0.718942 -0.128419  0.625090 -0.064832 -0.068210  0.051887   \n",
       "2     -0.713588  1.577942 -1.959490 -1.146558 -1.234197 -1.173061 -1.239559   \n",
       "3      0.594481 -0.836130 -0.048808  0.834860  0.938853  0.616833  1.008029   \n",
       "4      1.178619 -1.323631 -0.208031 -0.064685 -0.312151 -0.322027 -0.314852   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16507 -1.207859  1.648255 -0.924537  1.769755  1.601574  1.613658  1.681257   \n",
       "16508  0.020329  0.799814 -0.208031  0.656719  0.396191 -0.753253 -0.788994   \n",
       "16509  0.624437 -0.723629  0.428863 -0.075383  1.522335  1.077041  1.526703   \n",
       "16510  1.148663 -0.536128 -1.720655 -0.135383 -0.446617 -0.511731 -0.487743   \n",
       "16511  1.408280 -0.845505 -1.004149  1.228818  1.279818 -0.677723 -0.587287   \n",
       "\n",
       "             7         8         9         10   11   12   13   14   15  \n",
       "0      0.550573  0.061484  0.029981 -0.554024  1.0  0.0  0.0  0.0  0.0  \n",
       "1      5.878027  0.863266 -0.043355 -1.277473  1.0  0.0  0.0  0.0  0.0  \n",
       "2      3.760119  0.337310  0.037488 -1.171649  0.0  1.0  0.0  0.0  0.0  \n",
       "3      0.565199 -0.163434 -0.061519 -0.069204  1.0  0.0  0.0  0.0  0.0  \n",
       "4      0.883545  0.442889 -0.024570 -0.759023  0.0  0.0  0.0  0.0  1.0  \n",
       "...         ...       ...       ...       ...  ...  ...  ...  ...  ...  \n",
       "16507 -0.609498  0.082382 -0.018347 -0.403925  0.0  1.0  0.0  0.0  0.0  \n",
       "16508 -0.802491  5.784696 -0.017444 -0.604461  0.0  1.0  0.0  0.0  0.0  \n",
       "16509 -1.180081 -1.219584 -0.057354  3.854437  1.0  0.0  0.0  0.0  0.0  \n",
       "16510  0.458380  0.790731 -0.034167 -0.956917  0.0  1.0  0.0  0.0  0.0  \n",
       "16511 -0.282333  5.312479 -0.064144 -0.168978  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[16512 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-312382290f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune your model - cross_val_acore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.831350Z",
     "start_time": "2020-12-15T00:13:11.417Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.829356Z",
     "start_time": "2020-12-15T00:13:11.411Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_scores(scores, print_list_scores=False):\n",
    "    if print_list_scores:\n",
    "        print(\"Scores:\", list(scores))\n",
    "    \n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### Ensemble + Cross_val_score\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.831350Z",
     "start_time": "2020-12-15T00:13:11.415Z"
    }
   },
   "outputs": [],
   "source": [
    "forest_reg = RandomForestRegressor(n_estimators=10,\n",
    "                                   random_state=42,\n",
    "                                   verbose=0)\n",
    "\n",
    "forest_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.832348Z",
     "start_time": "2020-12-15T00:13:11.419Z"
    }
   },
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(forest_reg, \n",
    "                                X_train_prepared, \n",
    "                                y_train,\n",
    "                                scoring=\"neg_mean_squared_error\", \n",
    "                                cv=10)\n",
    "\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### GridSearch CV\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.835340Z",
     "start_time": "2020-12-15T00:13:11.424Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30],\n",
    "     'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False],\n",
    "    'n_estimators': [3, 10],\n",
    "     'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "\n",
    "grid_search = GridSearchCV(forest_reg,\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True) #If ``False``, the ``cv_results_`` attribute will not include training scores.\n",
    "\n",
    "grid_search.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter combination found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.836337Z",
     "start_time": "2020-12-15T00:13:11.426Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.836337Z",
     "start_time": "2020-12-15T00:13:11.428Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### RandomizedSearchCV\n",
    "        Para quando o espaço de hyperparamtros é maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.839329Z",
     "start_time": "2020-12-15T00:13:11.435Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rnd_search = RandomizedSearchCV(forest_reg,\n",
    "                                param_distributions=param_distribs,\n",
    "                                n_iter=10,\n",
    "                                cv=5,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                random_state=42)\n",
    "\n",
    "rnd_search.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.841324Z",
     "start_time": "2020-12-15T00:13:11.438Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.842323Z",
     "start_time": "2020-12-15T00:13:11.440Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # old solution\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.843320Z",
     "start_time": "2020-12-15T00:13:11.442Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.844316Z",
     "start_time": "2020-12-15T00:13:11.444Z"
    }
   },
   "outputs": [],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute a 95% confidence interval for the test RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.845313Z",
     "start_time": "2020-12-15T00:13:11.448Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compute the interval manually like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.846311Z",
     "start_time": "2020-12-15T00:13:11.451Z"
    }
   },
   "outputs": [],
   "source": [
    "m = len(squared_errors)\n",
    "mean = squared_errors.mean()\n",
    "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
    "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean - tmargin), np.sqrt(mean + tmargin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use a z-scores rather than t-scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.847308Z",
     "start_time": "2020-12-15T00:13:11.453Z"
    }
   },
   "outputs": [],
   "source": [
    "zscore = stats.norm.ppf((1 + confidence) / 2)\n",
    "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean - zmargin), np.sqrt(mean + zmargin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A full pipeline with both preparation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.847308Z",
     "start_time": "2020-12-15T00:13:11.457Z"
    }
   },
   "outputs": [],
   "source": [
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
    "full_pipeline_with_predictor.predict(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model persistence using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.848305Z",
     "start_time": "2020-12-15T00:13:11.460Z"
    }
   },
   "outputs": [],
   "source": [
    "my_model = full_pipeline_with_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.849303Z",
     "start_time": "2020-12-15T00:13:11.462Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(my_model, \"my_model.pkl\") # DIFF\n",
    "#...\n",
    "my_model_loaded = joblib.load(\"my_model.pkl\") # DIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example SciPy distributions for `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.850300Z",
     "start_time": "2020-12-15T00:13:11.464Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import geom, expon\n",
    "geom_distrib=geom(0.5).rvs(10000, random_state=42)\n",
    "expon_distrib=expon(scale=1).rvs(10000, random_state=42)\n",
    "plt.hist(geom_distrib, bins=50)\n",
    "plt.show()\n",
    "plt.hist(expon_distrib, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Try a Support Vector Machine regressor (`sklearn.svm.SVR`), with various hyperparameters such as `kernel=\"linear\"` (with various values for the `C` hyperparameter) or `kernel=\"rbf\"` (with various values for the `C` and `gamma` hyperparameters). Don't worry about what these hyperparameters mean for now. How does the best `SVR` predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.851298Z",
     "start_time": "2020-12-15T00:13:11.468Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "        {'kernel': ['rbf'], 'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "         'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ]\n",
    "\n",
    "svm_reg = SVR()\n",
    "grid_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model achieves the following score (evaluated using 5-fold cross validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.852295Z",
     "start_time": "2020-12-15T00:13:11.471Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_mse = grid_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much worse than the `RandomForestRegressor`. Let's check the best hyperparameters found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.853292Z",
     "start_time": "2020-12-15T00:13:11.474Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear kernel seems better than the RBF kernel. Notice that the value of `C` is the maximum tested value. When this happens you definitely want to launch the grid search again with higher values for `C` (removing the smallest values), because it is likely that higher values of `C` will be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Try replacing `GridSearchCV` with `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.854290Z",
     "start_time": "2020-12-15T00:13:11.478Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "# see https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "# for `expon()` and `reciprocal()` documentation and more probability distribution functions.\n",
    "\n",
    "# Note: gamma is ignored when kernel is \"linear\"\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model achieves the following score (evaluated using 5-fold cross validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.855287Z",
     "start_time": "2020-12-15T00:13:11.481Z"
    }
   },
   "outputs": [],
   "source": [
    "negative_mse = rnd_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is much closer to the performance of the `RandomForestRegressor` (but not quite there yet). Let's check the best hyperparameters found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.856284Z",
     "start_time": "2020-12-15T00:13:11.484Z"
    }
   },
   "outputs": [],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the search found a good set of hyperparameters for the RBF kernel. Randomized search tends to find better hyperparameters than grid search in the same amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the exponential distribution we used, with `scale=1.0`. Note that some samples are much larger or smaller than 1.0, but when you look at the log of the distribution, you can see that most values are actually concentrated roughly in the range of exp(-2) to exp(+2), which is about 0.1 to 7.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.857282Z",
     "start_time": "2020-12-15T00:13:11.488Z"
    }
   },
   "outputs": [],
   "source": [
    "expon_distrib = expon(scale=1.)\n",
    "samples = expon_distrib.rvs(10000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Exponential distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution we used for `C` looks quite different: the scale of the samples is picked from a uniform distribution within a given range, which is why the right graph, which represents the log of the samples, looks roughly constant. This distribution is useful when you don't have a clue of what the target scale is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.858279Z",
     "start_time": "2020-12-15T00:13:11.490Z"
    }
   },
   "outputs": [],
   "source": [
    "reciprocal_distrib = reciprocal(20, 200000)\n",
    "samples = reciprocal_distrib.rvs(10000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Reciprocal distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reciprocal distribution is useful when you have no idea what the scale of the hyperparameter should be (indeed, as you can see on the figure on the right, all scales are equally likely, within the given range), whereas the exponential distribution is best when you know (more or less) what the scale of the hyperparameter should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Try adding a transformer in the preparation pipeline to select only the most important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.858279Z",
     "start_time": "2020-12-15T00:13:11.495Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this feature selector assumes that you have already computed the feature importances somehow (for example using a `RandomForestRegressor`). You may be tempted to compute them directly in the `TopFeatureSelector`'s `fit()` method, however this would likely slow down grid/randomized search since the feature importances would have to be computed for every hyperparameter combination (unless you implement some sort of cache)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the number of top features we want to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.859276Z",
     "start_time": "2020-12-15T00:13:11.498Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look for the indices of the top k features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.860274Z",
     "start_time": "2020-12-15T00:13:11.501Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "top_k_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.861271Z",
     "start_time": "2020-12-15T00:13:11.503Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(attributes)[top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check that these are indeed the top k features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.862267Z",
     "start_time": "2020-12-15T00:13:11.506Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted(zip(feature_importances, attributes), reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good... Now let's create a new pipeline that runs the previously defined preparation pipeline, and adds top k feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.863265Z",
     "start_time": "2020-12-15T00:13:11.509Z"
    }
   },
   "outputs": [],
   "source": [
    "preparation_and_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.864263Z",
     "start_time": "2020-12-15T00:13:11.511Z"
    }
   },
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the features of the first 3 instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.865261Z",
     "start_time": "2020-12-15T00:13:11.513Z"
    }
   },
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's double check that these are indeed the top k features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.866257Z",
     "start_time": "2020-12-15T00:13:11.516Z"
    }
   },
   "outputs": [],
   "source": [
    "housing_prepared[0:3, top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works great!  :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Try creating a single pipeline that does the full data preparation plus the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.867256Z",
     "start_time": "2020-12-15T00:13:11.520Z"
    }
   },
   "outputs": [],
   "source": [
    "prepare_select_and_predict_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k)),\n",
    "    ('svm_reg', SVR(**rnd_search.best_params_))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.868252Z",
     "start_time": "2020-12-15T00:13:11.522Z"
    }
   },
   "outputs": [],
   "source": [
    "prepare_select_and_predict_pipeline.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the full pipeline on a few instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.869249Z",
     "start_time": "2020-12-15T00:13:11.525Z"
    }
   },
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:4]\n",
    "some_labels = housing_labels.iloc[:4]\n",
    "\n",
    "print(\"Predictions:\\t\", prepare_select_and_predict_pipeline.predict(some_data))\n",
    "print(\"Labels:\\t\\t\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the full pipeline seems to work fine. Of course, the predictions are not fantastic: they would be better if we used the best `RandomForestRegressor` that we found earlier, rather than the best `SVR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Automatically explore some preparation options using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.870247Z",
     "start_time": "2020-12-15T00:13:11.530Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'feature_selection__k': list(range(1, len(feature_importances) + 1))\n",
    "}]\n",
    "\n",
    "grid_search_prep = GridSearchCV(prepare_select_and_predict_pipeline, param_grid, cv=5,\n",
    "                                scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search_prep.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T00:13:19.871244Z",
     "start_time": "2020-12-15T00:13:11.532Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search_prep.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best imputer strategy is `most_frequent` and apparently almost all features are useful (15 out of 16). The last one (`ISLAND`) seems to just add some noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You already know quite a lot about Machine Learning. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
